{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check Pytorch\n",
    "!module avail pytorch\n",
    "#Load Pytorch\n",
    "!module load python3/3.8.6\n",
    "!module load pytorch/1.7.0\n",
    "!module load torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports here\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Sampler, BatchSampler \n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, ImageOps\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the original MNIST data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Data'\n",
    "train_dir = data_dir + '/training/fashion-mnist_train.csv'\n",
    "#valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/testing/fashion-mnist_test.csv'\n",
    "train_data = pd.read_csv(train_dir)\n",
    "test_data = pd.read_csv(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionDataset(Dataset):\n",
    "    \"\"\"User defined class to build a datset using Pytorch class Dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, data, transform = None):\n",
    "        \"\"\"Method to initilaize variables.\"\"\" \n",
    "        self.fashion_MNIST = list(data.values)\n",
    "        self.transform = transform\n",
    "        \n",
    "        label = []\n",
    "        image = []\n",
    "        \n",
    "        for i in self.fashion_MNIST:\n",
    "            # first column is of labels.\n",
    "            label.append(i[1])\n",
    "            image.append(i[2:])\n",
    "        self.labels = np.asarray(label)\n",
    "        # Dimension of Images = 28 * 28 * 1. where height = width = 28 and color_channels = 1.\n",
    "        self.images = np.asarray(image).reshape(-1, 28, 28, 1).astype('float32')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels[index]\n",
    "        image = self.images[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.is_available())\n",
    "# Transform data into Tensor that has a range from 0 to 1\n",
    "train_set = FashionDataset(train_data, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test_set = FashionDataset(test_data, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "print(np.size(train_set.images,0),np.size(train_set.images,1),np.size(train_set.images,2))\n",
    "print(np.size(test_set.images,0),np.size(test_set.images,1),np.size(test_set.images,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageSampler(Sampler):\n",
    "    def __init__(self, \n",
    "                 sample_idx,\n",
    "                 data_source='Data/training/fashion-mnist_train.csv'):\n",
    "        super().__init__(data_source)\n",
    "        self.sample_idx = sample_idx\n",
    "        self.df_images = pd.read_csv(data_source)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        image_ids = self.df_images['image_id'].loc[self.sample_idx]\n",
    "        return iter(image_ids)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sample_idx)\n",
    "\n",
    "class ImageBatchSampler(BatchSampler):\n",
    "    def __init__(self, \n",
    "                 sampler,\n",
    "                 aug_count=4,\n",
    "                 batch_size=100,\n",
    "                 drop_last=True):\n",
    "        super().__init__(sampler, batch_size, drop_last)\n",
    "        self.aug_count = aug_count\n",
    "        assert self.batch_size % self.aug_count == 0, 'Batch size must be an integer multiple of the aug_count.'\n",
    "        \n",
    "    def __iter__(self):\n",
    "        batch = []\n",
    "        \n",
    "        for image_id in self.sampler:\n",
    "            for i in range(self.aug_count):\n",
    "                batch.append(image_id)\n",
    "            if len(batch) == self.batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "        if len(batch) > 0 and not self.drop_last:\n",
    "            yield batch\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.drop_last:\n",
    "            return len(self.sampler) // self.batch_size\n",
    "        else:\n",
    "            return (len(self.sampler) + self.batch_size - 1) // self.batch_size\n",
    "            \n",
    "def create_split_loaders(dataset, split, aug_count, batch_size):\n",
    "    train_folds_idx = split[0]\n",
    "    valid_folds_idx = split[1]\n",
    "    train_sampler = ImageSampler(train_folds_idx)\n",
    "    valid_sampler = ImageSampler(valid_folds_idx)\n",
    "    train_batch_sampler = ImageBatchSampler(train_sampler, \n",
    "                                            aug_count, \n",
    "                                            batch_size)\n",
    "    valid_batch_sampler = ImageBatchSampler(valid_sampler, \n",
    "                                            aug_count=1, \n",
    "                                            batch_size=batch_size,\n",
    "                                            drop_last=False)\n",
    "    train_loader = DataLoader(dataset, batch_sampler=train_batch_sampler)\n",
    "    valid_loader = DataLoader(dataset, batch_sampler=valid_batch_sampler)\n",
    "    return (train_loader, valid_loader)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_split_loaders(dataset, cv_splits, aug_count=4, batch_size=100):\n",
    "    \"\"\"Create DataLoaders for each split\"\"\"\n",
    "    split_samplers = []\n",
    "    \n",
    "    for i in range(len(cv_splits)):\n",
    "        split_samplers.append(\n",
    "            create_split_loaders(dataset,\n",
    "                                 cv_splits[i], \n",
    "                                 aug_count, \n",
    "                                 batch_size)\n",
    "        )\n",
    "    return split_samplers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split and create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = StratifiedKFold(n_splits=6, shuffle=True, random_state=0)\n",
    "\n",
    "splits = []\n",
    "for train_idx, test_idx in splitter.split(train_data['image_id'],train_data['label']):\n",
    "    splits.append((train_idx, test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = get_all_split_loaders(train_set, splits, aug_count=2, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_label(label):\n",
    "    output_mapping = {\n",
    "                 0: \"T-shirt/Top\",\n",
    "                 1: \"Trouser\",\n",
    "                 2: \"Pullover\",\n",
    "                 3: \"Dress\",\n",
    "                 4: \"Coat\", \n",
    "                 5: \"Sandal\", \n",
    "                 6: \"Shirt\",\n",
    "                 7: \"Sneaker\",\n",
    "                 8: \"Bag\",\n",
    "                 9: \"Ankle Boot\"\n",
    "                 }\n",
    "    input = (label.item() if type(label) == torch.Tensor else label)\n",
    "    return output_mapping[input]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(FashionCNN, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=64*6*6, out_features=600)\n",
    "        self.drop = nn.Dropout2d(0.25)\n",
    "        self.fc2 = nn.Linear(in_features=600, out_features=120)\n",
    "        self.fc3 = nn.Linear(in_features=120, out_features=10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FashionCNN()\n",
    "model.to(device)\n",
    "\n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "count = 0\n",
    "# Lists for visualization of loss and accuracy \n",
    "loss_list = []\n",
    "valid_loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "# Lists for knowing classwise accuracy\n",
    "predictions_list = []\n",
    "labels_list = []\n",
    "for train_batch_loader, valid_batch_loader in tqdm(dataloaders):\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        print(epoch)\n",
    "        for images, labels in train_batch_loader:\n",
    "            # Transfering images and labels to GPU if available\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            train = Variable(images.view(10, 1, 28, 28))\n",
    "            labels = Variable(labels)\n",
    "\n",
    "            # Forward pass \n",
    "            outputs = model(train)\n",
    "            loss = error(outputs, labels)\n",
    "            \n",
    "            predictions = torch.max(outputs, 1)[1].to(device)\n",
    "            train_correct += (predictions == labels).sum()\n",
    "            train_total += len(labels)\n",
    "            train_accuracy = train_correct * 100 / train_total\n",
    "\n",
    "            # Initializing a gradient as 0 so there is no mixing of gradient among the batches\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #Propagating the error backward\n",
    "            loss.backward()\n",
    "\n",
    "            # Optimizing the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            count += 1\n",
    "\n",
    "            # Turn off gradients for validation, saves memory and computation\n",
    "            with torch.no_grad():\n",
    "            # Set the model to evaluation mode\n",
    "                model.eval()\n",
    "\n",
    "                # Validation pass\n",
    "\n",
    "                if not (count % 50):    # It's same as \"if count % 50 == 0\"\n",
    "                    total = 0\n",
    "                    correct = 0\n",
    "                    valid_loss = 0\n",
    "\n",
    "                    for images, labels in valid_batch_loader:\n",
    "                        images, labels = images.to(device), labels.to(device)\n",
    "                        labels_list.append(labels)\n",
    "\n",
    "                        validation = Variable(images.view(10, 1, 28, 28))\n",
    "\n",
    "                        outputs = model(images)\n",
    "\n",
    "                        valid_loss += error(outputs, labels)\n",
    "\n",
    "                        predictions = torch.max(outputs, 1)[1].to(device)\n",
    "                        predictions_list.append(predictions)\n",
    "                        correct += (predictions == labels).sum()\n",
    "\n",
    "                        total += len(labels)\n",
    "\n",
    "                    model.train()\n",
    "                    accuracy = correct * 100 / total\n",
    "                    loss_list.append(loss.data/len(train_batch_loader))\n",
    "                    valid_loss_list.append(valid_loss/len(valid_batch_loader))\n",
    "                    iteration_list.append(count)\n",
    "                    accuracy_list.append(accuracy)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Iteration: {}, Train_Loss: {}, Valid_Loss: {}, Train_Accuracy: {}, Valid_Accuracy: {}%\".format(count, loss.data/len(train_batch_loader), valid_loss/len(valid_batch_loader), train_accuracy, accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,loader):\n",
    "    predictions_arr = np.array([50])\n",
    "    true_labels_arr = np.array([50])\n",
    "\n",
    "    # Do validation on the test set\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        total = 0\n",
    "        correct = 0\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "    \n",
    "        for i, (images, labels) in enumerate(loader):\n",
    "    \n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "            \n",
    "            curr_label = labels.cpu().detach().flatten().numpy()\n",
    "            true_labels_arr = np.hstack((true_labels_arr, curr_label))\n",
    "            #test = Variable(images.view(10, 1, 28, 28))\n",
    "            try:\n",
    "                test = Variable(images.view(10, 1, 28, 28))\n",
    "            except BaseException:\n",
    "                test = Variable(images.view(5, 1, 28, 28))\n",
    "                \n",
    "            outputs = model(test)\n",
    "            probabilities = torch.exp(outputs)\n",
    "            #test_loss += error(outputs, labels)\n",
    "\n",
    "            predictions = torch.max(outputs, 1)[1].to(device)\n",
    "            curr_prediction = predictions.cpu().detach().numpy()\n",
    "            predictions_arr = np.hstack((predictions_arr, curr_prediction))\n",
    "            correct += (predictions == labels.flatten()).sum().item()\n",
    "            total += len(labels)\n",
    "         \n",
    "        print(correct, total)\n",
    "        accuracy = (correct / total) * 100\n",
    "\n",
    "\n",
    "        print(\"Test Accuracy: {}%\".format(accuracy)) \n",
    "        \n",
    "        predictions_arr = predictions_arr[1:]\n",
    "        true_labels_arr = true_labels_arr[1:]\n",
    "    \n",
    "    return accuracy, true_labels_arr, predictions_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_set, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy, true_labels, predictions = test(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(true_labels.shape)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test on different data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define MNIST categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionCategories:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.categories = {0: 'T-shirt/top', 1 : 'Trouser', 2: 'Pullover', 3: 'Dress', 4: 'Coat', 5: 'Sandal', 6: 'Shirt', 7: 'Sneaker', 8: 'Bag', 9: 'Ankle boot' }\n",
    "        \n",
    "    def __str__(self):\n",
    "        retstr = 'Categories:\\n'\n",
    "        for label, clothing in self.categories.items():\n",
    "            retstr += str(label) + ': ' + clothing + '\\n'\n",
    "        return retstr\n",
    "    \n",
    "categories = FashionCategories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in new testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_arr = np.load('imagesFashionImages.npy')\n",
    "label_arr = np.load('labelsFashionImages.npy')\n",
    "\n",
    "print(\"Layout\")\n",
    "print(\"Images: {}\".format(im_arr.shape))\n",
    "print(\"Lables: {}\".format(label_arr.shape))\n",
    "print()\n",
    "print(\"Examples\")\n",
    "\n",
    "fig, axs = plt.subplots(2, 4)\n",
    "fig.tight_layout()\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.imshow(im_arr[i])\n",
    "    ax.set_title(str(categories.categories[label_arr[i,0]]) + ' (' + str(int(label_arr[i,0])) +')')\n",
    "plt.show()\n",
    "plt.savefig('first_8_inverted.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading class for new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionImgData(Dataset):\n",
    "    \"\"\"User defined class to build a datset using Pytorch class Dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, image_data, label_data, transform = None):\n",
    "        \"\"\"Method to initilaize variables.\"\"\" \n",
    "        self.transform = transform\n",
    "        self.labels = label_data\n",
    "        # Dimension of Images = 28 * 28 * 3. where height = width = 28 and color_channels = 3.\n",
    "        self.images =  image_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels[index]\n",
    "        image = self.images[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define custom transforms and create loaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transforms_normfirst = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1552, 0.1725, 0.1782), (0.2477, 0.2616, 0.2658)),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((28,28))])\n",
    "\n",
    "mnist_transforms_normlast = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((28,28)),\n",
    "    transforms.Normalize((0.1682,),(0.2504,),)])\n",
    "\n",
    "fashion_data = FashionImgData(im_arr, label_arr, mnist_transforms_normlast)\n",
    "print(\"Number of samples: {}\".format(len(fashion_data.images)))\n",
    "fashionloader = DataLoader(dataset=fashion_data, batch_size = 10, shuffle = False)\n",
    "\n",
    "print(\"Train data shape: \")\n",
    "for i, (images, labels) in enumerate(fashionloader):\n",
    "    print(images.shape, labels.shape)\n",
    "    if i == 5: #print only first 10\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Examples grayscale:\")\n",
    "example = iter(fashionloader)\n",
    "images, labels = example.next()\n",
    "fig, axs = plt.subplots(2, 4)\n",
    "fig.tight_layout()\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.imshow(images[i][0], cmap= 'gray')\n",
    "    ax.set_title(str(categories.categories[labels[i].item()]) + ' (' + str(int(labels[i].item())) +')')\n",
    "plt.show()\n",
    "plt.savefig('first_8_grayAndSmall.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model on the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, true_labels, predictions = test(model,fashionloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(true_labels.shape)\n",
    "print(predictions.shape)\n",
    "print(true_labels[:20])\n",
    "print(predictions[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Example predictions:\")\n",
    "print()\n",
    "example = iter(fashionloader)\n",
    "images, labels = example.next()\n",
    "fig, axs = plt.subplots(2, 4)\n",
    "fig.tight_layout()\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.imshow(images[i][0], cmap= 'gray')\n",
    "    ax.set_title(str(categories.categories[predictions[i]]) + ' (' + str(int(predictions[i])) +')')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_truth, y_pred, num_cats):\n",
    "    n = len(y_truth)\n",
    "    mat = np.zeros(shape=(num_cats,num_cats))\n",
    "    for i in range(n):\n",
    "        mat[int(y_truth[i]),int(y_pred[i])] += 1\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
